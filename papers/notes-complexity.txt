Notes on the complexity of our Verification Games.

Type checking complexity:
 * Non-polymorphic type systems can often be checked, and even
   inferred, in linear time.
 * With sufficiently expressive type systems, type-checking is undecidable.
   The Curry-Howard isomorphism says that any proof can be encoded in a
   program's type.


Type inference complexity:
 * As a general rule, type inference is more expensive than type checking.
 * ML type-checking (which is actually type inference) is towers of
   exponentials; that is, a program of size O(n) can require O(2^2^2^...^2)
   time, where the exponents are n high.  This behavior never comes up in
   practice:  a programmer wouldn't write it, because it is too hard to
   understand.  Thus, ML programmers informally believe that ML
   type-checking is linear:  slower for big programs and faster for small
   programs.  Furthermore, if the ML type of every expression is explicitly
   written (so that no inference is required), then I believe ML type
   checking is cheap.

As an aside, for the particular security-related type systems I am focusing
on, the cost of type-checking is modest.  They are polymorphic.  Types are
written explicitly on all procedure signatures, and type inference is only
required within procedure boundaries.  But, writing those explicit types is
a burden for programmers.

In Verification Games, the players are essentially doing type inference.

 * If the program is verifiable, then type inference will succeed, and it
   will do so relatively quickly thanks to the simplicity of the current
   type systems.  (I don't yet know how to represent more complex type
   systems in a fun game that utilizes humans' physical intuition, but I
   will be working on that.)
   If type inference succeeds, we might as well have used a program
   analysis rather than crowd-sourcing it to humans.

 * If the program is NOT verifiable, then current type inference systems
   give poor error messages.  They will indicate SOME inconsistency in the
   program, but it may not be near the root cause nor near what a
   programmer would choose to change.  Furthermore, there are a lot of
   possible choices of error messages, and current systems choose among
   them arbitrarily.

I hope that players will outperform type inference systems in deciding
where to put the cheats (the buzzsaws).  They will use their intuition,
higher-level reasoning and pattern-matching, and observation of animated
actual executions.  If the buzzsaws are placed minimally and accurately,
then each buzzsaw location indicates either a bug or safe-but-unverifiable
code that requires human inspection by a verification expert.

Thus, when a player finishes a game, the real value is in where the
buzzsaws are.

An interesting theoretical question is:  How hard is the problem the
players are solving?  That is, how hard is it to find the minimal number of
cheats (buzzsaws) that are required to solve the game?  (There are other
interesting questions, of course!)  I haven't thought deeply about this.
One naive algorithm would try every possible partial solution, then every
possible set of cheats upon that -- but at first glance it's somewhat
daunting.

This question might be related to the following ones about a more abstract
game:  You start with a possibly-unsatisfiable SAT formula.  Your goal is
to make it satisfiable.  You are allowed to make certain changes to the
formula:
 * remove one variable from all clauses
 * remove one variable from one clause
 * invert the sense of one variable in all clauses
 * invert the sense of one variable in one clauses
 * remove one clause
 * invert the sense of one clause
 * others?

Maybe the game lets you perform only one type of action (but as many of
them as needed), or maybe it lets you perform multiple types of actions.

The question is:  How hard is it to find the minimal number of changes that
makes the formula satisfiable?
